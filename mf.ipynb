{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization on MovieLens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a small subset of MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast SGD based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "px.defaults.template = 'plotly_dark'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 250\n",
    "LR = 1e-2\n",
    "LATENT_DIM = 2\n",
    "LAMBDA = 1e-5\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "\n",
    "unique_users = df.userId.unique()\n",
    "unique_movies = df.movieId.unique()\n",
    "\n",
    "# Create user-item matrix\n",
    "r_ui = torch.zeros(len(unique_users), len(unique_movies)) * float('nan')\n",
    "for i, j, r in zip(df.userId.factorize()[0], df.movieId.factorize()[0], df.rating):\n",
    "    r_ui[i, j] = r\n",
    "\n",
    "# Split data\n",
    "rows, cols = r_ui.nan_to_num(0.0).to_sparse().indices()\n",
    "idx = range(len(rows))\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Initialize parameters\n",
    "W = nn.Parameter(torch.rand(len(unique_users), LATENT_DIM) / LATENT_DIM)\n",
    "H = nn.Parameter(torch.rand(LATENT_DIM, len(unique_movies)) / LATENT_DIM)\n",
    "\n",
    "l2 = nn.MSELoss()\n",
    "optim = torch.optim.Adam([W, H], lr=LR)\n",
    "\n",
    "losses = []\n",
    "for it in tqdm(range(EPOCHS)):\n",
    "    V = W @ H\n",
    "    u = rows[train_idx]\n",
    "    i = cols[train_idx]\n",
    "    loss = l2(V[u, i], r_ui[u, i])\n",
    "    loss_reg = loss + LAMBDA * W.norm(p=2) + LAMBDA * H.norm(p=2)\n",
    "    optim.zero_grad()\n",
    "    loss_reg.backward()\n",
    "    optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        V = W @ H\n",
    "        u = rows[test_idx]\n",
    "        i = cols[test_idx]\n",
    "        loss_test = l2(V[u, i], r_ui[u, i])\n",
    "    losses.append((loss.item(), loss_test.item()))\n",
    "\n",
    "for idx in range(5):\n",
    "    V = W @ H\n",
    "    u = rows[test_idx[idx]]\n",
    "    i = cols[test_idx[idx]]\n",
    "\n",
    "    print(f'Predicted: {V[u, i].item()}')\n",
    "    print(f'Actual: {r_ui[u, i].item()}')\n",
    "    print(f'Difference: {abs(V[u, i].item() - r_ui[u, i].item())}\\n')\n",
    "\n",
    "px.line(losses).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit MF\n",
    "[Explicit Matrix Factorization: ALS, SGD, and All That Jazz](https://blog.insightdatascience.com/explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import plotly.express as px\n",
    "px.defaults.template = 'plotly_dark'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1000\n",
    "LATENT_DIM = 2\n",
    "LR = 0.01\n",
    "LAMBDA = 2e-1\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "unique_users = df.userId.unique()\n",
    "unique_movies = df.movieId.unique()\n",
    "\n",
    "# Create user-item matrix\n",
    "r_ui = torch.zeros(len(unique_users), len(unique_movies))\n",
    "for i, j, r in zip(df.userId.factorize()[0], df.movieId.factorize()[0], df.rating):\n",
    "    r_ui[i, j] = r\n",
    "\n",
    "# Craft user and item indices\n",
    "rows = df.userId.factorize()[0]\n",
    "cols = df.movieId.factorize()[0]\n",
    "idx = range(len(rows))\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2)\n",
    "\n",
    "# Initialize latent factors\n",
    "x_u = torch.rand(LATENT_DIM, r_ui.shape[0]) / LATENT_DIM\n",
    "y_i = torch.rand(LATENT_DIM, r_ui.shape[1]) / LATENT_DIM\n",
    "\n",
    "mean = df.rating.mean()\n",
    "b_u = torch.from_numpy(df.groupby('userId').mean().rating.values)\n",
    "b_i = torch.from_numpy(df.groupby('movieId').mean().rating.values)\n",
    "\n",
    "errors = []\n",
    "for it in range(EPOCHS):\n",
    "    error = []\n",
    "\n",
    "    for idx in range(0, len(train_idx), BATCH_SIZE):\n",
    "        # User indices\n",
    "        u = torch.from_numpy(rows[train_idx[idx:idx+BATCH_SIZE]])\n",
    "        # Item indices\n",
    "        i = torch.from_numpy(cols[train_idx[idx:idx+BATCH_SIZE]])\n",
    "\n",
    "        # Predicted rating\n",
    "        r_hat_ui = (mean + b_u[u] + b_i[i] + (x_u[:, u].T @ y_i[:, i])).float()\n",
    "\n",
    "        e_ui = r_ui[u, i] - r_hat_ui\n",
    "\n",
    "        # Update biases\n",
    "        b_u[u] = b_u[u] + LR * (e_ui - LAMBDA * b_u[u, None]).mean(1)\n",
    "        b_i[i] = b_i[i] + LR * (e_ui - LAMBDA * b_i[None, i]).mean(0)\n",
    "\n",
    "        # Update latent factors\n",
    "        x_u[:, u] = x_u[:, u] + LR * (e_ui[None] * y_i[:, None, i] - LAMBDA * x_u[:, u, None]).mean(2)\n",
    "        y_i[:, i] = y_i[:, i] + LR * (e_ui[None] * x_u[:, u, None] - LAMBDA * y_i[:, None, i]).mean(1)\n",
    "\n",
    "        mse = e_ui.square().mean()\n",
    "        error.append(mse)\n",
    "\n",
    "    mse = sum(error).item() / len(error)  \n",
    "\n",
    "    error = []\n",
    "    for idx in range(0, len(test_idx), BATCH_SIZE):\n",
    "        u = torch.from_numpy(rows[test_idx[idx:idx+BATCH_SIZE]])\n",
    "        i = torch.from_numpy(cols[test_idx[idx:idx+BATCH_SIZE]])\n",
    "\n",
    "        r_hat_ui = (mean + b_u[u] + b_i[i] + (x_u[:, u].T @ y_i[:, i])).float()\n",
    "        e_ui = r_ui[u, i] - r_hat_ui\n",
    "\n",
    "        mse_test = e_ui.square().mean()\n",
    "        error.append(mse_test)\n",
    "\n",
    "    mse_test = sum(error).item() / len(error)  \n",
    "\n",
    "    errors.append((mse, mse_test))\n",
    "    print(f'{mse = } {mse_test = }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
